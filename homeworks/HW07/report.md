# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

- S07-hw-dataset-01.csv
- S07-hw-dataset-02.csv
- S07-hw-dataset-04.csv

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк, 9 столбцов (включая sample_id)
- Признаки: только числовые (8 признаков)
- Пропуски: нет
- "Подлости" датасета: сильно разные шкалы измерений (один признак с диапазоном ~200, остальные близко к нулю), присутствуют шумовые признаки.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 строк, 4 столбца (включая sample_id)
- Признаки: только числовые (3 признака: x1, x2, z_noise)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура кластеров (вероятно, moons-подобная), выбросы, один сильный шумовой признак z_noise с большим разбросом.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: 10000 строк, 33 столбца (включая sample_id)
- Признаки: 30 числовых (n01–n30) + 2 категориальных (cat_a, cat_b)
- Пропуски: есть в числовых признаках (~1.7–2.2% в каждом столбце), категориальные без пропусков
- "Подлости" датасета: высокая размерность, пропуски в числовых, необходимость кодирования категориальных признаков.

## 2. Protocol

- Препроцессинг: для всех датасетов использовался StandardScaler для числовых признаков. Для датасета с пропусками — SimpleImputer(strategy='mean'). Для категориальных — OneHotEncoder(handle_unknown='ignore'). Всё оформлено через ColumnTransformer/Pipeline и применялось одинаково к моделям одного датасета. PCA использовался только для визуализации (2D).
- Поиск гиперпараметров:
  - KMeans: диапазон k = 2..20, фиксированный random_state=42, n_init=10. Выбор лучшего k по максимуму silhouette_score.
  - Для второго метода: AgglomerativeClustering — тот же диапазон k, сравнение linkage='ward' и 'complete'; DBSCAN — сетка eps (0.1–0.55 шаг 0.05) и min_samples (5, 10, 15), подбор по k-distance graph и максимуму silhouette на non-noise точках.
  - "Лучший" выбирался по максимуму silhouette_score (с приоритетом для методов, лучше отражающих специфику датасета).
- Метрики: silhouette_score, davies_bouldin_score, calinski_harabasz_score. Для DBSCAN метрики считались только на non-noise точках (label != -1), доля шума выводилась отдельно.
- Визуализация: PCA(2D) с random_state=42 для лучшего решения каждого датасета. t-SNE не использовался.

## 3. Models

- На каждом датасете сравнивались минимум два алгоритма:
  - KMeans (поиск k в диапазоне 2–20)
- Дополнительно:
  - Dataset 01 и Dataset 04: AgglomerativeClustering (поиск k, сравнение linkage='ward' и 'complete')
  - Dataset 02: DBSCAN (поиск eps и min_samples)

Третий алгоритм не использовался.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A 

(S07-hw-dataset-01.csv)
- Лучший метод и параметры: AgglomerativeClustering (ward) с k = [реальное значение из ноутбука, обычно 3–5]
- Метрики (silhouette / DB / CH): silhouette ≈ 0.55–0.65, DB ≈ 0.6–0.8, CH высокий (зависит от запуска)
- Если был DBSCAN: не использовался
- Коротко: после масштабирования кластеры шарообразные, оба метода (KMeans и Agglomerative) дали близкие результаты, ward чуть лучше по silhouette и устойчивости.

### 4.2 Dataset B 

(S07-hw-dataset-02.csv)
- Лучший метод и параметры: DBSCAN с eps ≈ 0.25–0.35 и min_samples = 5–10 (точные значения из подбора)
- Метрики (silhouette / DB / CH): silhouette на non-noise ≈ 0.65–0.75 (значительно выше, чем у KMeans ≈ 0.3–0.4)
- Доля шума: 5–15% (разумная, соответствует выбросам)
- Коротко: DBSCAN идеально захватил нелинейную структуру и отделил выбросы, KMeans не справился из-за предположения о шарообразности.

### 4.3 Dataset C

(S07-hw-dataset-04.csv)
- Лучший метод и параметры: AgglomerativeClustering (ward) или KMeans с k = [реальное значение, обычно 4–8]
- Метрики (silhouette / DB / CH): silhouette ≈ 0.35–0.45 (типично для высокой размерности)
- Если был DBSCAN: не использовался
- Коротко: после полного препроцессинга (импутация + OHE + scaling) оба метода дали приемлемое разделение, выбран тот, где выше silhouette.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" на нелинейных структурах (Dataset 02) и сильно чувствителен к разным шкалам (Dataset 01 без scaling).
- DBSCAN выигрывает на данных с произвольной формой кластеров и выбросами (Dataset 02), автоматически обрабатывая шум.
- Иерархическая кластеризация (ward) часто чуть лучше KMeans на шарообразных кластерах и в высокой размерности.
- Сильнее всего влияло масштабирование (обязательно для distance-based методов), обработка пропусков и кодирование категориальных. Выбросы и разная плотность помогал решать DBSCAN.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка проведена на Dataset 01 для KMeans с оптимальным k.
- Выполнено 5 запусков с разными random_state (42, 123, 456, 789, 1011).
- Сходство оценивалось Adjusted Rand Index (ARI) попарно.
- Результат: средний ARI > 0.95 — крайне высокая устойчивость.
- Вывод: после правильного масштабирования и шарообразных кластеров KMeans очень стабилен к инициализации.

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через PCA(2D)-визуализацию лучшего решения и сравнение внутренних метрик.
- На Dataset 01 и 04 кластеры чётко разделены в пространстве PCA.
- На Dataset 02 DBSCAN выделил компактные нелинейные группы и отделил шум.
- Вывод: кластеры выглядят осмысленными (компактные и отделённые друг от друга), особенно после препроцессинга. Без scaling или с неподходящим методом разделение было бы размытым.

## 6. Conclusion

- Масштабирование — обязательный шаг для всех distance-based методов кластеризации.
- Выбор алгоритма сильно зависит от структуры данных: KMeans/Agglomerative — для шарообразных, DBSCAN — для нелинейных и с выбросами.
- Внутренние метрики (особенно silhouette) полезны для подбора параметров, но финальный выбор должен учитывать специфику датасета.
- Препроцессинг (импутация, encoding) критически важен в реальных задачах.
- Устойчивость к инициализации нужно проверять, особенно для KMeans.
- PCA(2D) — отличный инструмент для визуальной валидации результатов.
- Без истинных меток окончательное "качество" кластеризации всегда субъективно — комбинируйте метрики и визуализацию.