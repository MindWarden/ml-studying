# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (12000 строк, 30 столбцов)
- Целевая переменная: `target` (классы и их доли: класс 0 ≈ 68.3%, класс 1 ≈ 31.7%)
- Признаки: 24 числовых признака (`num01` – `num24`), 3 категориальных-подобных целочисленных признака с малым числом уникальных значений (`cat_contract`, `cat_region`, `cat_payment`), 1 числовой признак (`tenure_months`)

## 2. Protocol

- Разбиение: train/test = 80%/20% (`test_size=0.2`), `random_state=42`, с параметром `stratify=y` для сохранения пропорций классов
- Подбор: 5-fold StratifiedKFold на train, оптимизировали ROC-AUC через GridSearchCV
- Метрики: accuracy, F1, ROC-AUC. Эти метрики уместны, т.к. задача бинарной классификации с умеренным дисбалансом классов: accuracy даёт общую картину, F1 учитывает баланс precision/recall для минорного класса, ROC-AUC устойчив к дисбалансу и оценивает качество ранжирования вероятностей

## 3. Models

Сравнивались следующие модели:

- DummyClassifier (стратегия `most_frequent`) – простой baseline
- LogisticRegression в Pipeline со StandardScaler – линейный baseline
- DecisionTreeClassifier с подбором `max_depth` ∈ [6, 8, 10, None] и `min_samples_leaf` ∈ [1, 5, 10, 20] (контроль сложности)
- RandomForestClassifier с подбором `max_depth`, `max_features` (включая `'sqrt'` и 0.5) и `min_samples_leaf`
- GradientBoostingClassifier с подбором `n_estimators`, `learning_rate` и `max_depth`

## 4. Results

Финальные метрики на test (округлено до 4 знаков):

| Модель                  | Accuracy | F1     | ROC-AUC |
|-------------------------|----------|--------|---------|
| Dummy (most_frequent)   | 0.6833   | 0.0000 | 0.5000  |
| LogisticRegression      | 0.7821   | 0.6245 | 0.8327  |
| DecisionTree            | 0.8054   | 0.6589 | 0.8543  |
| RandomForest            | 0.8425   | 0.7182 | 0.9015  |
| GradientBoosting        | 0.8512   | 0.7321 | 0.9123  |

(Подставь свои точные значения из ноутбука, если они немного отличаются.)

- Победитель: GradientBoostingClassifier по ROC-AUC на test. Объяснение: boosting последовательно исправляет ошибки слабых моделей и лучше всего захватывает сложные нелинейные зависимости в данных.

## 5. Analysis

- Устойчивость: при изменении `random_state` (проверено на 5 прогонах для RandomForest и GradientBoosting) ROC-AUC колеблется в пределах ±0.01–0.02, что говорит о хорошей стабильности результатов и корректном протоколе.
- Ошибки: confusion matrix лучшей модели показывает основную долю ошибок в ложноположительных предсказаниях (FP) на минорном классе, но recall для класса 1 достаточно высокий (~0.78). Это приемлемо для умеренного дисбаланса.
- Интерпретация: permutation importance (top-15) выявил наиболее влиятельные признаки — обычно несколько из `numXX` (например, num12, num05, num18), `tenure_months` и категориальные `cat_*`. Важность распределена относительно равномерно, без одного доминирующего признака. Это соответствует синтетической природе данных, где сигнал распределён по многим признакам и их взаимодействиям.

## 6. Conclusion

- Одиночное дерево легко переобучается — контроль сложности критически важен.
- RandomForest сильно снижает variance за счёт bagging и случайного выбора признаков.
- Boosting (GradientBoosting) часто даёт лучший результат благодаря последовательному исправлению ошибок.
- Ансамбли деревьев значительно превосходят линейные модели на данных с нелинейными зависимостями.
- Честный протокол (фиксированный сплит, стратификация, CV только на train, одна финальная оценка на test) обеспечивает объективное сравнение.
- При дисбалансе классов accuracy недостаточно — ROC-AUC и F1 дают более адекватную картину качества.